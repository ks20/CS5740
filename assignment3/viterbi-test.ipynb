{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/shei/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/shei/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/shei/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import sklearn\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer #stemming is probably stupid\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter, defaultdict\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv(\"./data/train_x.csv\", index_col=0)\n",
    "train_y = pd.read_csv(\"./data/train_y.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(raw, sep):\n",
    "    output = []\n",
    "    sentence = []\n",
    "    for tag in raw:\n",
    "        if tag==sep:\n",
    "            output.append(sentence)\n",
    "            sentence = []\n",
    "        sentence.append(tag)\n",
    "    output.append(sentence)\n",
    "    return output[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = make_list(train_y[\"tag\"].values, \"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grams(y_train, n=3):\n",
    "    tran_counts = defaultdict(int)\n",
    "    state_counts = defaultdict(int)\n",
    "    for doc in y_train:\n",
    "        state = n*[\"O\"]\n",
    "        for i in range(1, len(doc)):\n",
    "            if not doc[i]:\n",
    "                break\n",
    "            tran_counts[(tuple(state),doc[i])] += 1\n",
    "            state_counts[tuple(state)] += 1\n",
    "            state.pop(0)\n",
    "            state.append(doc[i])\n",
    "        tran_counts[(tuple(state), \"END\")] += 1\n",
    "        state_counts[tuple(state)] += 1\n",
    "    return tran_counts, state_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_4_counts, state_4_counts = create_grams(y_train, 4)\n",
    "tran_3_counts, state_3_counts = create_grams(y_train, 3)\n",
    "tran_2_counts, state_2_counts = create_grams(y_train, 2)\n",
    "tran_1_counts, state_1_counts = create_grams(y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('O',): 1387,\n",
       "             ('NNP',): 67431,\n",
       "             (',',): 35475,\n",
       "             ('CD',): 26323,\n",
       "             ('NNS',): 43879,\n",
       "             ('JJ',): 45356,\n",
       "             ('MD',): 7204,\n",
       "             ('VB',): 19353,\n",
       "             ('DT',): 59928,\n",
       "             ('NN',): 96805,\n",
       "             ('IN',): 72097,\n",
       "             ('.',): 28837,\n",
       "             ('VBZ',): 16170,\n",
       "             ('VBG',): 11013,\n",
       "             ('CC',): 17297,\n",
       "             ('VBD',): 21357,\n",
       "             ('VBN',): 14622,\n",
       "             ('RB',): 22445,\n",
       "             ('TO',): 16250,\n",
       "             ('PRP',): 12837,\n",
       "             ('RBR',): 1257,\n",
       "             ('WDT',): 3217,\n",
       "             ('VBP',): 9395,\n",
       "             ('RP',): 1912,\n",
       "             ('PRP$',): 6065,\n",
       "             ('JJS',): 1407,\n",
       "             ('POS',): 6478,\n",
       "             ('``',): 5229,\n",
       "             ('EX',): 645,\n",
       "             (\"''\",): 5105,\n",
       "             ('WP',): 1741,\n",
       "             (':',): 3602,\n",
       "             ('JJR',): 2394,\n",
       "             ('WRB',): 1566,\n",
       "             ('$',): 5125,\n",
       "             ('NNPS',): 2049,\n",
       "             ('WP$',): 129,\n",
       "             ('(',): 1021,\n",
       "             (')',): 1030,\n",
       "             ('PDT',): 296,\n",
       "             ('RBS',): 320,\n",
       "             ('FW',): 204,\n",
       "             ('UH',): 64,\n",
       "             ('SYM',): 30,\n",
       "             ('LS',): 37,\n",
       "             ('#',): 91})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_1_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_counts = {1: tran_1_counts, \n",
    "               2: tran_2_counts, \n",
    "               3: tran_3_counts, \n",
    "               4: tran_4_counts}\n",
    "state_counts = {1: state_1_counts, \n",
    "               2: state_2_counts, \n",
    "               3: state_3_counts, \n",
    "               4: state_4_counts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_counts = Counter(list(zip(train_y[\"tag\"], train_x[\"word\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts = Counter(train_y[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tag_counts[\"O\"] #impossible to transition to \"Doc Start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_tags = list(set([el[1] for el in tran_counts[1].keys()]))\n",
    "all_tags = possible_tags + [\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(set(train_x[\"word\"])) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37506"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x = pd.read_csv(\"./data/test_x.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = make_list(dev_x[\"word\"].values, \"-DOCSTART-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transition exists 85 - 89.77% accuracy - beam search 92% accuracy\n",
    "def calc_prob_backoff(state, tag):\n",
    "    n = len(state)\n",
    "    substate = tuple(state[:])\n",
    "    while tran_counts[n][(substate, tag)] == 0:\n",
    "        substate = tuple(state[-n:])\n",
    "        n -= 1\n",
    "        \n",
    "        if n == 0: #transition from unigram doesn't exist\n",
    "            s = sum([value for key, value in state_counts[1].items()]) #summing over all of state counts\n",
    "            return state_counts[1][(tag,)] / s #return probability of tag existing at all\n",
    "\n",
    "    num = tran_counts[n][substate, tag]\n",
    "    den = state_counts[n][substate]\n",
    "    return num/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Beam Search\n",
    "k = 1\n",
    "results = []\n",
    "delta = 1 # below this # of occurences we ignore, for kneser-ney smoothing\n",
    "counter = 0\n",
    "beam = 10\n",
    "n=3\n",
    "for doc in x_test:\n",
    "    state = n*[\"O\"]\n",
    "    paths = {tuple(state): 0}\n",
    "    if counter % 10 == 0: \n",
    "        print(counter)\n",
    "    counter += 1\n",
    "    for i in range(1, len(doc)):\n",
    "        probs = {}\n",
    "        for path, value in paths.items():\n",
    "            state = path[-n:]\n",
    "            for tag in possible_tags:\n",
    "    ### BACKOFF ###\n",
    "                prob = np.log(calc_prob_backoff(state, tag)) ##transition probability\n",
    "\n",
    "    ### WITHOUT BACKOFF ###\n",
    "    #             if(tran_counts[(tuple(state), tag)] == 0): \n",
    "    #                 prob = -10 #give some small minimimal probability **maybe play with this later?**\n",
    "    #             else:\n",
    "    #                 prob = np.log(tran_counts[(tuple(state), tag)]/state_counts[tuple(state)])\n",
    "    #                 prob = max(prob, -10) #set a floor to the min probability\n",
    "\n",
    "                ### K Smoothing ###\n",
    "                prob += np.log((emit_counts[(tag, doc[i])] + k)/(tag_counts[tag] + k*vocab_size)) #emission probability\n",
    "\n",
    "                ### Without K Smoothing ###\n",
    "#               prob += np.log((emit_counts[(tag, doc[i])])/(tag_counts[tag]))\n",
    "\n",
    "                probs[tuple(list(path)+[tag])] = prob + value\n",
    "        \n",
    "        best_n_paths = sorted([(v, i, k) for i, (k, v) in enumerate(probs.items())])[-beam:]\n",
    "#         print(best_n_paths)\n",
    "        paths = dict([(k, v) for v, i, k in best_n_paths])\n",
    "        assert len(paths) == beam\n",
    "    results.append(best_n_paths[0][2][n-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi\n",
    "from itertools import product\n",
    "for s in product(possible_tags + [\"O\"], repeat=3):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Viterbi:\n",
    "smooth_k = 1\n",
    "results = []\n",
    "counter = 0\n",
    "beam = 10\n",
    "n=2\n",
    "final_results = []\n",
    "for doc in x_test:\n",
    "    if counter % 1 == 0: \n",
    "        print(\"doc:\", counter, \"of \", len(x_test))\n",
    "    counter += 1\n",
    "    init_state = n*[\"O\"]\n",
    "    path_probs = [defaultdict(lambda: float(\"-inf\"))]\n",
    "    path_probs[-1][tuple(init_state)] = 0\n",
    "    backpointer = [{tuple(init_state): None}]\n",
    "\n",
    "    for i in range(1, len(doc)):\n",
    "        if i % 100 == 0: \n",
    "            print(i,\" words in \", len(doc))\n",
    "\n",
    "        prev_states = list(backpointer[-1].keys())\n",
    "#         print(prev_states)\n",
    "        path_probs.append(defaultdict(lambda: float(\"-inf\")))\n",
    "        backpointer.append({})\n",
    "        for new_state in product(all_tags, repeat=n):\n",
    "            old_to_new_probs = []\n",
    "            for old_tag in all_tags: \n",
    "                old_state = tuple([old_tag] + list(new_state[:-(n-1)]))\n",
    "                new_tag = new_state[-1]\n",
    "                ### BACKOFF ###\n",
    "                prob = np.log(calc_prob_backoff(old_state, new_tag)) ##transition probability\n",
    "\n",
    "                ### K Smoothing ###\n",
    "                prob += np.log((emit_counts[(new_tag, doc[i])] + smooth_k)/(tag_counts[new_tag] + smooth_k*vocab_size)) #emission probability\n",
    "                \n",
    "                prob += path_probs[-2][old_state]\n",
    "                old_to_new_probs.append(prob)\n",
    "#                 if old_state == (\"O\", \"O\"):\n",
    "#                     print(old_state, \"old_state\")\n",
    "#                     print(new_state, \"new_state\")\n",
    "#                     print(new_tag, \"new_tag\")\n",
    "#                     print(calc_prob_backoff(old_state, new_tag), 'state')\n",
    "#                     print(prob, \"prob\")\n",
    "            index = np.argmax(old_to_new_probs)\n",
    "            path_probs[-1][new_state] = old_to_new_probs[index]\n",
    "            backpointer[-1][new_state] = tuple([all_tags[index]] + list(new_state[:-(n-1)]))\n",
    "    state = max(path_probs[-1], key=path_probs[-1].get)\n",
    "    results = []\n",
    "    results.append(state[-1])\n",
    "    for bp in list(reversed(backpointer))[:-1]:\n",
    "        state = bp[state]\n",
    "        results.append(state[-1])\n",
    "    final_results.append(list(reversed(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_results = np.concatenate(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236577</th>\n",
       "      <td>236577</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236578</th>\n",
       "      <td>236578</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236579</th>\n",
       "      <td>236579</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236580</th>\n",
       "      <td>236580</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236581</th>\n",
       "      <td>236581</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236582 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  tag\n",
       "0            0    O\n",
       "1            1  NNP\n",
       "2            2   MD\n",
       "3            3   VB\n",
       "4            4   JJ\n",
       "...        ...  ...\n",
       "236577  236577  PRP\n",
       "236578  236578   RB\n",
       "236579  236579   IN\n",
       "236580  236580  PRP\n",
       "236581  236581    .\n",
       "\n",
       "[236582 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_data=np.concatenate([np.arange(len(flatten_results)).reshape(-1,1),np.asarray(flatten_results).reshape(-1,1)], axis=1)\n",
    "results_df = pd.DataFrame(data=results_data, columns=[\"id\", \"tag\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"./results/test_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'NNP', 'MD', ..., 'IN', 'PRP', '.'], dtype='<U4')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('final_results', final_resulst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
